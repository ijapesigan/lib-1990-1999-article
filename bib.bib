@Article{Andrews-1991,
  author = {Donald W. K. Andrews},
  date = {1991-05},
  journaltitle = {Econometrica},
  title = {Heteroskedasticity and autocorrelation consistent covariance matrix estimation},
  doi = {10.2307/2938229},
  number = {3},
  pages = {817},
  volume = {59},
  abstract = {This paper is concerned with the estimation of covariance matrices in the presence of heteroskedasticity and autocorrelation of unknown forms. Currently available estimators that are designed for this context depend upon the choice of a lag truncation parameter and a weighting scheme. Results in the literature provide a condition on the growth rate of the lag truncation parameter as $T \to \infty$ that is sufficient for consistency. No results are available, however, regarding the choice of lag truncation parameter for a fixed sample size, regarding data-dependent automatic lag truncation parameters, or regarding the choice of weighting scheme. In consequence, available estimators are not entirely operational and the relative merits of the estimators are unknown. This paper addresses these problems. The asymptotic truncated mean squared errors of estimators in a given class are determined and compared. Asymptotically optimal kernel/weighting scheme and bandwidth/lag truncation parameters are obtained using an asymptotic truncated mean squared error criterion. Using these results, data-dependent automatic bandwidth/lag truncation parameters are introduced. The finite sample properties of the estimators are analyzed via Monte Carlo simulation.},
  publisher = {{JSTOR}},
  annotation = {regression, regression-hc},
}

@Article{Andrews-1992,
  author = {Donald W. K. Andrews and J. Christopher Monahan},
  date = {1992-07},
  journaltitle = {Econometrica},
  title = {An improved heteroskedasticity and autocorrelation consistent covariance matrix estimator},
  doi = {10.2307/2951574},
  number = {4},
  pages = {953},
  volume = {60},
  publisher = {{JSTOR}},
  annotation = {regression, regression-hc},
}

@Article{Bollen-Stine-1990,
  author = {Kenneth A. Bollen and Robert Stine},
  date = {1990},
  journaltitle = {Sociological Methodology},
  title = {Direct and indirect effects: Classical and bootstrap estimates of variability},
  doi = {10.2307/271084},
  pages = {115},
  volume = {20},
  abstract = {The decomposition of effects in structural equation models has been of considerable interest to social scientists. Finite-sample or asymptotic results for the sampling distribution of estimators of direct effects are widely available. Statistical inferences about indirect effects have relied exclusively on asymptotic methods which assume that the limiting distribution of the estimator is normal, with a standard error derived from the delta method. We examine bootstrap procedures as another way to generate standard errors and confidence intervals and to estimate the sampling distributions of estimators of direct and indirect effects. We illustrate the classical and the bootstrap methods with three empirical examples. We find that in a moderately large sample, the bootstrap distribution of an estimator is close to that assumed with the classical and delta methods but that in small samples, there are some differences. Bootstrap methods provide a check on the classical and delta methods when the latter are applied under less than ideal conditions.},
  publisher = {{JSTOR}},
}

@Article{Li-Raghunathan-Rubin-1991,
  author = {K. H. Li and Trivellore Eachambadi Raghunathan and Donald B. Rubin},
  date = {1991-12},
  journaltitle = {Journal of the American Statistical Association},
  title = {Large-sample significance levels from multiply imputed data using moment-based statistics and an {$F$} reference distribution},
  doi = {10.1080/01621459.1991.10475152},
  number = {416},
  pages = {1065--1073},
  volume = {86},
  abstract = {We present a procedure for computing significance levels from data sets whose missing values have been multiply imputed data. This procedure uses moment-based statistics, $m \leq 3$ repeated imputations, and an F reference distribution. When $m = \infty$, we show first that our procedure is essentially the same as the ideal procedure in cases of practical importance and, second, that its deviations from the ideal are basically a function of the coefficient of variation of the canonical ratios of complete to observed information. For small $m$ our procedure's performance is largely governed by this coefficient of variation and the mean of these ratios. Using simulation techniques with small $m$, we compare our procedure's actual and nominal large-sample significance levels and conclude that it is essentially calibrated and thus represents a definite improvement over previously available procedures. Furthermore, we compare the large-sample power of the procedure as a function of $m$ and other factors, such as the dimensionality of the estimand and fraction of missing information, to provide guidance on the choice of the number of imputations; generally, we find the loss of power due to small $m$ to be quite modest in cases likely to occur in practice.},
  publisher = {Informa {UK} Limited},
  keywords = {imputation, missing data, nonresponse, tests of significance},
  annotation = {missing, missing-mi},
}

@Article{Oud-vandenBercken-Essers-1990,
  author = {Johan H. Oud and John H. {van den Bercken} and Raymond J. Essers},
  date = {1990-12},
  journaltitle = {Applied Psychological Measurement},
  title = {Longitudinal factor score estimation using the {Kalman} filter},
  doi = {10.1177/014662169001400406},
  number = {4},
  pages = {395--418},
  volume = {14},
  abstract = {The advantages of the Kalman filter as a factor score estimator in the presence of longitudinal data are described. Because the Kalman filter presupposes the availability of a dynamic state space model, the state space model is reviewed first, and it is shown to be translatable into the LISREL model. Several extensions of the LISREL model specification are discussed in order to enhance the applicability of the Kalman filter for behavioral research data. The Kalman filter and its main properties are summarized. Relationships are shown between the Kalman filter and two well-known cross-sectional factor score estimators: the regression estimator, and the Bartlett estimator. The indeterminacy problem of factor scores is also discussed in the context of Kalman filtering, and the differences are described between Kalman filtering on the basis of a zero-means and a structured-means LISREL model. By using a structured-means LISREL model, the Kalman filter is capable of estimating absolute latent developmental curves. An educational research example is presented. Index terms: factor score estimation, indeterminacy of factor scores, Kalman filter, L,ISREL longitudinal LISREL modeling, longitudinal factor analysis, state space modeling.},
  publisher = {{SAGE} Publications},
}

@Article{Robey-Barcikowski-1992,
  author = {Randall R. Robey and Robert S. Barcikowski},
  date = {1992-11},
  journaltitle = {British Journal of Mathematical and Statistical Psychology},
  title = {Type {I} error and the number of iterations in {Monte Carlo} studies of robustness},
  doi = {10.1111/j.2044-8317.1992.tb00993.x},
  number = {2},
  pages = {283--288},
  volume = {45},
  abstract = {A recent survey of simulation studies concluded that an overwhelming majority of papers do not report a rationale for the decision regarding the number of Monte Carlo iterations. A surprisingly large number of reports do not contain a justifiable definition of robustness and many studies are conducted with an insufficient number of iterations to achieve satisfactory statistical conclusion validity. The implication is that we do not follow our own advice regarding the management of Type I and Type II errors when conducting Monte Carlo experiments. This paper reports a straightforward application of a well-known procedure for the purpose of objectively determining the exact number of iterations necessary to confidently detect departures from robustness in Monte Carlo results. A table of the number of iterations necessary to detect departures from a series of nominal Type I error rates is included.},
  publisher = {Wiley},
  annotation = {robustness},
}
