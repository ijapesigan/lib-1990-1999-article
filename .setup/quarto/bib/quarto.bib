@Article{Andrews-1991,
  author = {Donald W. K. Andrews},
  date = {1991-05},
  journaltitle = {Econometrica},
  title = {Heteroskedasticity and autocorrelation consistent covariance matrix estimation},
  doi = {10.2307/2938229},
  number = {3},
  pages = {817},
  volume = {59},
  abstract = {This paper is concerned with the estimation of covariance matrices in the presence of heteroskedasticity and autocorrelation of unknown forms. Currently available estimators that are designed for this context depend upon the choice of a lag truncation parameter and a weighting scheme. Results in the literature provide a condition on the growth rate of the lag truncation parameter as $T \to \infty$ that is sufficient for consistency. No results are available, however, regarding the choice of lag truncation parameter for a fixed sample size, regarding data-dependent automatic lag truncation parameters, or regarding the choice of weighting scheme. In consequence, available estimators are not entirely operational and the relative merits of the estimators are unknown. This paper addresses these problems. The asymptotic truncated mean squared errors of estimators in a given class are determined and compared. Asymptotically optimal kernel/weighting scheme and bandwidth/lag truncation parameters are obtained using an asymptotic truncated mean squared error criterion. Using these results, data-dependent automatic bandwidth/lag truncation parameters are introduced. The finite sample properties of the estimators are analyzed via Monte Carlo simulation.},
  publisher = {{JSTOR}},
  annotation = {regression, regression-hc},
}

@Article{Andrews-Monahan-1992,
  author = {Donald W. K. Andrews and J. Christopher Monahan},
  date = {1992-07},
  journaltitle = {Econometrica},
  title = {An improved heteroskedasticity and autocorrelation consistent covariance matrix estimator},
  doi = {10.2307/2951574},
  number = {4},
  pages = {953},
  volume = {60},
  publisher = {{JSTOR}},
  annotation = {regression, regression-hc},
}

@Article{Berkey-Hoaglin-AntczakBouckoms-etal-1998,
  author = {C. S. Berkey and D. C. Hoaglin and A. Antczak-Bouckoms and F. Mosteller and G. A. Colditz},
  date = {1998-11},
  journaltitle = {Statistics in Medicine},
  title = {Meta-analysis of multiple outcomes by regression with random effects},
  doi = {10.1002/(sici)1097-0258(19981130)17:22<2537::aid-sim953>3.0.co;2-c},
  issn = {1097-0258},
  number = {22},
  pages = {2537--2550},
  volume = {17},
  abstract = {Earlier work showed how to perform fixed-effects meta-analysis of studies or trials when each provides results on more than one outcome per patient and these multiple outcomes are correlated. That fixed-effects generalized-least-squares approach analyzes the multiple outcomes jointly within a single model, and it can include covariates, such as duration of therapy or quality of trial, that may explain observed heterogeneity of results among the trials. Sometimes the covariates explain all the heterogeneity, and the fixed-effects regression model is appropriate. However, unexplained heterogeneity may often remain, even after taking into account known or suspected covariates. Because fixed-effects models do not make allowance for this remaining unexplained heterogeneity, the potential exists for bias in estimated coefficients, standard errors and p-values. We propose two random-effects approaches for the regression meta-analysis of multiple correlated outcomes. We compare their use with fixed-effects models and with separate-outcomes models in a meta-analysis of periodontal clinical trials. A simulation study shows the advantages of the random-effects approach. These methods also facilitate meta-analysis of trials that compare more than two treatments.},
  publisher = {Wiley},
}

@Article{Bollen-Stine-1990,
  author = {Kenneth A. Bollen and Robert Stine},
  date = {1990},
  journaltitle = {Sociological Methodology},
  title = {Direct and indirect effects: Classical and bootstrap estimates of variability},
  doi = {10.2307/271084},
  pages = {115},
  volume = {20},
  abstract = {The decomposition of effects in structural equation models has been of considerable interest to social scientists. Finite-sample or asymptotic results for the sampling distribution of estimators of direct effects are widely available. Statistical inferences about indirect effects have relied exclusively on asymptotic methods which assume that the limiting distribution of the estimator is normal, with a standard error derived from the delta method. We examine bootstrap procedures as another way to generate standard errors and confidence intervals and to estimate the sampling distributions of estimators of direct and indirect effects. We illustrate the classical and the bootstrap methods with three empirical examples. We find that in a moderately large sample, the bootstrap distribution of an estimator is close to that assumed with the classical and delta methods but that in small samples, there are some differences. Bootstrap methods provide a check on the classical and delta methods when the latter are applied under less than ideal conditions.},
  publisher = {{JSTOR}},
}

@Article{Celeux-Soromenho-1996,
  author = {Gilles Celeux and Gilda Soromenho},
  date = {1996-09},
  journaltitle = {Journal of Classification},
  title = {An entropy criterion for assessing the number of clusters in a mixture model},
  doi = {10.1007/bf01246098},
  issn = {1432-1343},
  number = {2},
  pages = {195--212},
  volume = {13},
  abstract = {In this paper, we consider an entropy criterion to estimate the number of clusters arising from a mixture model. This criterion is derived from a relation linking the likelihood and the classification likelihood of a mixture. Its performance is investigated through Monte Carlo experiments, and it shows favorable results compared to other classical criteria.},
  publisher = {Springer Science and Business Media LLC},
}

@Article{Clark-Watson-1991,
  author = {Lee Anna Clark and David Watson},
  date = {1991-08},
  journaltitle = {Journal of Abnormal Psychology},
  title = {Tripartite model of anxiety and depression: Psychometric evidence and taxonomic implications},
  doi = {10.1037/0021-843x.100.3.316},
  issn = {0021-843X},
  number = {3},
  pages = {316--336},
  volume = {100},
  abstract = {Reviews psychometric and other evidence relevant to mixed anxiety-depression. Properties of anxiety and depression measures, including the convergent and discriminant validity of self- and clinical ratings, and interrater reliability, are examined in patient and normal samples. Results suggest that anxiety and depression can be reliably and validly assessed; moreover, although these disorders share a substantial component of general affective distress, they can be differentiated on the basis of factors specific to each syndrome. L. A. Clark and D. Watson also review evidence for these specific factors, examining the influence of context and scale content on ratings, factor analytic studies, and the role of low positive affect in depression. With these data, Clark and Watson argue for a tripartite structure consisting of general distress, physiological hyperarousal (specific anxiety), and anhedonia (specific depression), and they propose a diagnosis of mixed anxiety-depression.},
  publisher = {American Psychological Association (APA)},
}

@Article{Collins-Wugalter-1992,
  author = {Linda M. Collins and Stuart E. Wugalter},
  date = {1992-01},
  journaltitle = {Multivariate Behavioral Research},
  title = {Latent class models for stage-sequential dynamic latent variables},
  doi = {10.1207/s15327906mbr2701_8},
  issn = {1532-7906},
  number = {1},
  pages = {131--157},
  volume = {27},
  abstract = {Stage-sequential dynamic latent variables are of interest in many longitudinal studies. Measurement theory for these latent variables, called Latent Transition Analysis (LTA), can be found in recent generalizations of latent class theory. LTA expands the latent Markov model to allow applications to more complex latent variables and the use of multiple indicators. Because complex latent class models result in sparse contingency tables, that may lead to poor parameter estimation, a simulation study was conducted in order to determine whether model parameters are recovered adequately by LTA, and whether additional indicators result in better measurement or in impossibly sparse tables. The results indicated that parameter recovery was satisfactory overall, although as expected the standard errors were large in some conditions with few subjects. The simulation also indicated that at least within the conditions examined here, the benefits of adding indicators outweigh the costs. Additional indicators improved standard errors, even in conditions producing extremely sparse tables. An example of LTA analysis of empirical data on math skill development is presented.},
  publisher = {Informa UK Limited},
}

@Article{Cooper-Frone-Russell-etal-1995,
  author = {M. Lynne Cooper and Michael R. Frone and Marcia Russell and Pamela Mudar},
  date = {1995-11},
  journaltitle = {Journal of Personality and Social Psychology},
  title = {Drinking to regulate positive and negative emotions: A motivational model of alcohol use},
  doi = {10.1037/0022-3514.69.5.990},
  issn = {0022-3514},
  number = {5},
  pages = {990--1005},
  volume = {69},
  abstract = {The present study proposed and tested a motivational model of alcohol use in which people are hypothesized to use alcohol to regulate both positive and negative emotions. Two central premises underpin this model: (a) that enhancement and coping motives for alcohol use are proximal determinants of alcohol use and abuse through which the influence of expectancies, emotions, and other individual differences are mediated and (b) that enhancement and coping motives represent phenomenologically distinct behaviors having both unique antecedents and consequences. This model was tested in 2 random samples (1 of adults, 1 of adolescents) using a combination of moderated regression and path analysis corrected for measurement error. Results revealed strong support for the hypothesized model in both samples and indicate the importance of distinguishing psychological motives for alcohol use.},
  publisher = {American Psychological Association (APA)},
}

@Article{DeNeve-Cooper-1998,
  author = {Kristina M. DeNeve and Harris Cooper},
  date = {1998},
  journaltitle = {Psychological Bulletin},
  title = {The happy personality: A meta-analysis of 137 personality traits and subjective well-being},
  doi = {10.1037/0033-2909.124.2.197},
  issn = {0033-2909},
  number = {2},
  pages = {197--229},
  volume = {124},
  abstract = {This meta-analysis used 9 literature search strategies to examine 137 distinct personality constructs as correlates of subjective well-being (SWB). Personality was found to be equally predictive of life satisfaction, happiness, and positive affect, but significantly less predictive of negative affect. The traits most closely associated with SWB were repressive-defensiveness, trust, emotional stability, locus of control-chance, desire for control, hardiness, positive affectivity, private collective self-esteem, and tension. When personality traits were grouped according to the Big Five factors, Neuroticism was the strongest predictor of life satisfaction, happiness, and negative affect. Positive affect was predicted equally well by Extraversion and Agreeableness. The relative importance of personality for predicting SWB, how personality might influence SWB, and limitations of the present review are discussed.},
  publisher = {American Psychological Association (APA)},
}

@Article{Dishion-McMahon-1998,
  author = {Thomas J. Dishion and Robert J. McMahon},
  date = {1998-03},
  journaltitle = {Clinical Child and Family Psychology Review},
  title = {Parental monitoring and the prevention of child and adolescent problem behavior: A conceptual and empirical formulation},
  doi = {10.1023/a:1021800432380},
  issn = {1573-2827},
  number = {1},
  pages = {61--75},
  volume = {1},
  abstract = {The present report accomplishes three goals. First, to provide an empirical rationale for placing parental monitoring of children's adaptations as a key construct in development and prevention research. Second, to stimulate more research on parental monitoring and provide an integrative framework for various research traditions as well as developmental periods of interest. Third, to discuss current methodological issues that are developmentally and culturally sensitive and based on sound measurement. Possible intervention and prevention strategies that specifically target parental monitoring are discussed.},
  publisher = {Springer Science and Business Media LLC},
}

@Article{Dumenci-Windle-1996,
  author = {Levent Dumenci and Michael Windle},
  date = {1996-07},
  journaltitle = {Multivariate Behavioral Research},
  title = {A latent trait-state model of adolescent depression using the {Center for Epidemiologic Studies-Depression Scale}},
  doi = {10.1207/s15327906mbr3103_3},
  issn = {1532-7906},
  number = {3},
  pages = {313--330},
  volume = {31},
  abstract = {Utilized the latent trait-state model for estimating stable and changing components of depressive symptomology in adolescents. The factorial structure of the Center for Epidemiologic Studies-Depression Scale (CES-D) was assessed separately for males and females at 4 measurement occasions, at 6-mo intervals. The variance decomposition of general trait, state, specific trait, and random error parameters for the CES-D scores was estimated simultaneously and tested statistically. Parameter estimates indicated that the CES-D measured both trait- and state-depression about equally well, and that the trait-specific variance parameter was statistically significant, but substantially smaller than those associated with general trait- and state-depression. Findings are discussed with regard to depressive mood fluctuations among adolescents and the potential usefulness of the latent trait-state model to capture such dynamic features of development.},
  publisher = {Informa UK Limited},
}

@Article{Eilers-Marx-1996,
  author = {Paul H. C. Eilers and Brian D. Marx},
  date = {1996-05},
  journaltitle = {Statistical Science},
  title = {Flexible smoothing with {B-splines} and penalties},
  doi = {10.1214/ss/1038425655},
  issn = {0883-4237},
  number = {2},
  volume = {11},
  abstract = {$B$-splines are attractive for nonparametric modelling, but choosing the optimal number and positions of knots is a complex task. Equidistant knots can be used, but their small and discrete number allows only limited control over smoothness and fit. We propose to use a relatively large number of knots and a difference penalty on coefficients of adjacent $B$-splines. We show connections to the familiar spline penalty on the integral of the squared second derivative. A short overview of $B$-splines, of their construction and of penalized likelihood is presented. We discuss properties of penalized $B$-splines and propose various criteria for the choice of an optimal penalty parameter. Nonparametric logistic regression, density estimation and scatterplot smoothing are used as examples. Some details of the computations are presented.},
  publisher = {Institute of Mathematical Statistics},
}

@Article{Hoogland-Boomsma-1998,
  author = {Jeffrey J. Hoogland and Anne Boomsma},
  date = {1998-02},
  journaltitle = {Sociological Methods \& Research},
  title = {Robustness studies in covariance structure modeling: An overview and a meta-analysis},
  doi = {10.1177/0049124198026003003},
  issn = {1552-8294},
  number = {3},
  pages = {329--367},
  volume = {26},
  abstract = {In covariance structure modeling several estimation methods are available. The robustness of an estimator against specific violations of assumptions can be determined empirically by means of a Monte Carlo study. Many such studies in covariance structure analysis have been published, but the conclusions frequently seem to contradict each other An overview of robustness studies in covariance structure analysis is given, and an attempt is made to generalize their findings. Robustness studies are described and distinguished from each other systematically by means of certain characteristics. These characteristics serve as explanatory variables in a meta-analysis concerning the behavior of parameter estimators, standard error estimators, and goodness-of-fit statistics when the model is correctly specified.},
  publisher = {SAGE Publications},
}

@Article{Kenny-Zautra-1995,
  author = {David A. Kenny and Alex Zautra},
  date = {1995},
  journaltitle = {Journal of Consulting and Clinical Psychology},
  title = {The trait-state-error model for multiwave data},
  doi = {10.1037/0022-006x.63.1.52},
  issn = {0022-006X},
  number = {1},
  pages = {52--59},
  volume = {63},
  abstract = {Although researchers in clinical psychology routinely gather data in which many individuals respond at multiple times, there is not a standard way to analyze such data. A new approach for the analysis of such data is described. It is proposed that a person's current standing on a variable is caused by 3 sources of variance: a term that does not change (trait), a term that changes (state), and a random term (error). It is shown how structural equation modeling can be used to estimate such a model. An extended example is presented in which the correlations between variables are quite different at the trait, state, and error levels.},
  publisher = {American Psychological Association (APA)},
}

@Article{Li-Raghunathan-Rubin-1991,
  author = {K. H. Li and Trivellore Eachambadi Raghunathan and Donald B. Rubin},
  date = {1991-12},
  journaltitle = {Journal of the American Statistical Association},
  title = {Large-sample significance levels from multiply imputed data using moment-based statistics and an {$F$} reference distribution},
  doi = {10.1080/01621459.1991.10475152},
  number = {416},
  pages = {1065--1073},
  volume = {86},
  abstract = {We present a procedure for computing significance levels from data sets whose missing values have been multiply imputed data. This procedure uses moment-based statistics, $m \leq 3$ repeated imputations, and an F reference distribution. When $m = \infty$, we show first that our procedure is essentially the same as the ideal procedure in cases of practical importance and, second, that its deviations from the ideal are basically a function of the coefficient of variation of the canonical ratios of complete to observed information. For small $m$ our procedure's performance is largely governed by this coefficient of variation and the mean of these ratios. Using simulation techniques with small $m$, we compare our procedure's actual and nominal large-sample significance levels and conclude that it is essentially calibrated and thus represents a definite improvement over previously available procedures. Furthermore, we compare the large-sample power of the procedure as a function of $m$ and other factors, such as the dimensionality of the estimand and fraction of missing information, to provide guidance on the choice of the number of imputations; generally, we find the loss of power due to small $m$ to be quite modest in cases likely to occur in practice.},
  publisher = {Informa {UK} Limited},
  keywords = {imputation, missing data, nonresponse, tests of significance},
  annotation = {missing, missing-mi},
}

@Article{Lyapunov-1992,
  author = {Alexandr Mikhailovich Lyapunov},
  date = {1992-03},
  journaltitle = {International Journal of Control},
  title = {The general problem of the stability of motion},
  doi = {10.1080/00207179208934253},
  issn = {1366-5820},
  number = {3},
  pages = {531--534},
  volume = {55},
  publisher = {Informa UK Limited},
}

@Article{MacKinnon-1994,
  author = {David P. MacKinnon},
  date = {1994},
  journaltitle = {NIDA research monograph},
  title = {Analysis of mediating variables in prevention and intervention research},
  pages = {127--153},
  volume = {139},
  abstract = {Mediational analysis is one way to test specific hypotheses derived from theory. Although this analysis has been suggested in the prevention literature, mediation analysis rarely is conducted. As the field of prevention matures, more questions about how prevention programs work (or fail to work) will emerge. Studies of mediation can address these questions, thereby reducing the cost and enhancing the impact of prevention programs. The methods outlined here can be applied in the evaluation of primary, secondary, and tertiary prevention programs. Since most prevention studies include measurement of some mediating constructs, mediation effects can be assessed on many existing data sets. Mediation analysis can be used to test ideas about prevention.},
  keywords = {Data Interpretation, Statistical; Health Behavior; Humans; Models, Statistical; Primary Prevention, methods; Research Design; Substance-Related Disorders, prevention & control},
  annotation = {mediation-prevention},
}

@Article{Mackinnon-Dwyer-1993,
  author = {David P. Mackinnon and James H. Dwyer},
  date = {1993-04},
  journaltitle = {Evaluation Review},
  title = {Estimating mediated effects in prevention studies},
  doi = {10.1177/0193841x9301700202},
  number = {2},
  pages = {144--158},
  volume = {17},
  abstract = {The purpose of this article is to describe statistical procedures to assess how prevention and intervention programs achieve their effects. The analyses require the measurement of intervening or mediating variables hypothesized to represent the causal mechanism by which the prevention program achieves its effects. Methods to estimate mediation are illustrated in the evaluation of a health promotion program designed to reduce dietary cholesterol and a school-based drug prevention program. The methods are relatively easy to apply and the information gained from such analyses should add to our understanding of prevention.},
  publisher = {{SAGE} Publications},
  annotation = {mediation-prevention},
}

@Article{Muthen-Curran-1997,
  author = {Bengt O. Muth{\a'e}n and Patrick J. Curran},
  date = {1997-12},
  journaltitle = {Psychological Methods},
  title = {General longitudinal modeling of individual differences in experimental designs: A latent variable framework for analysis and power estimation},
  doi = {10.1037/1082-989x.2.4.371},
  number = {4},
  pages = {371--402},
  volume = {2},
  abstract = {The generality of latent variable modeling of individual differences in development over time is demonstrated with a particular emphasis on randomized intervention studies. First, a brief overview is given of biostatistical and psychometric approaches to repeated measures analysis. Second, the generality of the psychometric approach is indicated by some nonstandard models. Third, a multiple-population analysis approach is proposed for the estimation of treatment effects. The approach clearly describes the treatment effect as development that differs from normative, control-group development. This framework allows for interactions between treatment and initial status in their effects on development. Finally, an approach for the estimation of power to detect treatment effects in this framework is demonstrated. Illustrations of power calculations are carried out with artificial data, varying the sample sizes, number of timepoints, and treatment effect sizes. Real data are used to illustrate analysis strategies and power calculations. Further modeling extensions are discussed.},
  publisher = {American Psychological Association ({APA})},
}

@Article{Oehlert-1992,
  author = {Gary W. Oehlert},
  date = {1992-02},
  journaltitle = {The American Statistician},
  title = {A note on the delta method},
  doi = {10.1080/00031305.1992.10475842},
  issn = {1537-2731},
  number = {1},
  pages = {27--29},
  volume = {46},
  abstract = {The delta method is an intuitive technique for approximating the moments of functions of random variables. This note reviews the delta method and conditions under which delta-method approximate moments are accurate.},
  keywords = {approximate moments, asymptotic approximations, Taylor series},
  publisher = {Informa UK Limited},
}

@Article{Oud-vandenBercken-Essers-1990,
  author = {Johan H. Oud and John H. {van den Bercken} and Raymond J. Essers},
  date = {1990-12},
  journaltitle = {Applied Psychological Measurement},
  title = {Longitudinal factor score estimation using the {Kalman} filter},
  doi = {10.1177/014662169001400406},
  number = {4},
  pages = {395--418},
  volume = {14},
  abstract = {The advantages of the Kalman filter as a factor score estimator in the presence of longitudinal data are described. Because the Kalman filter presupposes the availability of a dynamic state space model, the state space model is reviewed first, and it is shown to be translatable into the LISREL model. Several extensions of the LISREL model specification are discussed in order to enhance the applicability of the Kalman filter for behavioral research data. The Kalman filter and its main properties are summarized. Relationships are shown between the Kalman filter and two well-known cross-sectional factor score estimators: the regression estimator, and the Bartlett estimator. The indeterminacy problem of factor scores is also discussed in the context of Kalman filtering, and the differences are described between Kalman filtering on the basis of a zero-means and a structured-means LISREL model. By using a structured-means LISREL model, the Kalman filter is capable of estimating absolute latent developmental curves. An educational research example is presented. Index terms: factor score estimation, indeterminacy of factor scores, Kalman filter, L,ISREL longitudinal LISREL modeling, longitudinal factor analysis, state space modeling.},
  publisher = {{SAGE} Publications},
}

@Article{Politis-Romano-1994,
  author = {Dimitris N. Politis and Joseph P. Romano},
  date = {1994-12},
  journaltitle = {Journal of the American Statistical Association},
  title = {The stationary bootstrap},
  doi = {10.1080/01621459.1994.10476870},
  issn = {1537-274X},
  number = {428},
  pages = {1303--1313},
  volume = {89},
  abstract = {This article introduces a resampling procedure called the stationary bootstrap as a means of calculating standard errors of estimators and constructing confidence regions for parameters based on weakly dependent stationary observations. Previously, a technique based on resampling blocks of consecutive observations was introduced to construct confidence intervals for a parameter of the m-dimensional joint distribution of m consecutive observations, where m is fixed. This procedure has been generalized by constructing a ``blocks of blocks'' resampling scheme that yields asymptotically valid procedures even for a multivariate parameter of the whole (i.e., infinite-dimensional) joint distribution of the stationary sequence of observations. These methods share the construction of resampling blocks of observations to form a pseudo-time series, so that the statistic of interest may be recalculated based on the resampled data set. But in the context of applying this method to stationary data, it is natural to require the resampled pseudo-time series to be stationary (conditional on the original data) as well. Although the aforementioned procedures lack this property, the stationary procedure developed here is indeed stationary and possesses other desirable properties. The stationary procedure is based on resampling blocks of random length, where the length of each block has a geometric distribution. In this article, fundamental consistency and weak convergence properties of the stationary resampling scheme are developed.},
  publisher = {Informa UK Limited},
}

@Article{Robey-Barcikowski-1992,
  author = {Randall R. Robey and Robert S. Barcikowski},
  date = {1992-11},
  journaltitle = {British Journal of Mathematical and Statistical Psychology},
  title = {Type {I} error and the number of iterations in {Monte Carlo} studies of robustness},
  doi = {10.1111/j.2044-8317.1992.tb00993.x},
  number = {2},
  pages = {283--288},
  volume = {45},
  abstract = {A recent survey of simulation studies concluded that an overwhelming majority of papers do not report a rationale for the decision regarding the number of Monte Carlo iterations. A surprisingly large number of reports do not contain a justifiable definition of robustness and many studies are conducted with an insufficient number of iterations to achieve satisfactory statistical conclusion validity. The implication is that we do not follow our own advice regarding the management of Type I and Type II errors when conducting Monte Carlo experiments. This paper reports a straightforward application of a well-known procedure for the purpose of objectively determining the exact number of iterations necessary to confidently detect departures from robustness in Monte Carlo results. A table of the number of iterations necessary to detect departures from a series of nominal Type I error rates is included.},
  publisher = {Wiley},
  annotation = {robustness},
}

@Article{Saunders-Assland-Babor-etal-1993,
  author = {John B. Saunders and Olaf G. Aasland and Thomas F. Babor and Juan R. {de la Fuente} and Marcus Grant},
  date = {1993-06},
  journaltitle = {Addiction},
  title = {Development of the {Alcohol Use Disorders Identification Test (AUDIT)}: {WHO Collaborative Project on Early Detection of Persons with Harmful Alcohol Consumption-II}},
  doi = {10.1111/j.1360-0443.1993.tb02093.x},
  issn = {1360-0443},
  number = {6},
  pages = {791--804},
  volume = {88},
  abstract = {The Alcohol Use Disorders Identification Test (AUDIT) has been developed from a six-country WHO collaborative project as a screening instrument for hazardous and harmful alcohol consumption. It is a 10-item questionnaire which covers the domains of alcohol consumption, drinking behaviour, and alcohol-related problems. Questions were selected from a 150-item assessment schedule (which was administered to 1888 persons attending representative primary health care facilities) on the basis of their representativeness for these conceptual domains and their perceived usefulness for intervention. Responses to each question are scored from 0 to 4, giving a maximum possible score of 40. Among those diagnosed as having hazardous or harmful alcohol use, 92\% had an AUDIT score of 8 or more, and 94\% of those with non-hazardous consumption had a score of less than 8. AUDIT provides a simple method of early detection of hazardous and harmful alcohol use in primary health care settings and is the first instrument of its type to be derived on the basis of a cross-national study.},
  publisher = {Wiley},
}

@Article{Schulenberg-OMalley-Bachman-etal-1996,
  author = {John E. Schulenberg and Patrick M. O'Malley and Jerald G. Bachman and Katherine N. Wadsworth and Lloyd D. Johnston},
  date = {1996-05},
  journaltitle = {Journal of Studies on Alcohol},
  title = {Getting drunk and growing up: trajectories of frequent binge drinking during the transition to young adulthood},
  doi = {10.15288/jsa.1996.57.289},
  issn = {1934-2683},
  number = {3},
  pages = {289--304},
  volume = {57},
  abstract = {Objective: The purpose of this study was: (1) to identify different trajectories of frequent binge drinking during the transition to young adulthood; (2) to validate the trajectories by relating them to behaviors and attitudes concerning alcohol and other drug use; and (3) to distinguish among the trajectories according to demographic characteristics and lifestyle experiences typical of the transition to young adulthood. Method: Four waves of national panel data were obtained from the Monitoring the Future project; 9,945 weighted cases from the 1976-85 high school senior year cohorts were surveyed at biennial intervals between ages 18 and 24. Frequent binge drinking was defined as having five or more drinks in a row at least twice in the past two weeks. Results: Six distinct frequent binge drinking trajectory groups were specified a priori and confirmed with cluster analysis: Never, Rare, Chronic, Decreased, Increased and ``Fling.'' Repeated measures ANOVAS revealed that the trajectories corresponded to patterns of change and stability in problems with alcohol, attitudes about heavy drinking, peer heavy drinking and illicit drug use. Results from logistic regression analyses predicting diverging and converging trajectories provided some support for the general hypothesis that trajectories of Chronic and Increased frequent binge drinking over time are associated with difficulties in negotiating the transition to young adulthood. Conclusions: The findings provide strong evidence for wide developmental variation in drinking patterns in the population, variation that is obscured by more aggregate-level considerations. The developmental variation in frequent binge drinking during the transition to young adulthood reflects systematic variation in success and difficulties with negotiating the transition.},
  publisher = {Alcohol Research Documentation, Inc.},
}

@Article{Shapiro-Browne-1990,
  author = {A. Shapiro and M.W. Browne},
  date = {1990},
  journaltitle = {Linear Algebra and its Applications},
  title = {On the treatment of correlation structures as covariance structures},
  doi = {10.1016/0024-3795(90)90362-g},
  issn = {0024-3795},
  pages = {567--587},
  volume = {127},
  abstract = {Necessary and sufficient conditions are provided for minimum discrepancy methods, intended for covariance structures, to retain their asymptotic properties in the analysis of correlation structures. Examples of correlation structures satisfying these conditions are considered, and alternative discrepancy functions, which are always appropriate for correlation structures under normality assumptions, are discussed.},
  publisher = {Elsevier BV},
}

@Article{Stoffer-Wall-1991,
  author = {David S. Stoffer and Kent D. Wall},
  title = {Bootstrapping state-space models: {Gaussian} maximum likelihood estimation and the {Kalman} filter},
  number = {416},
  pages = {1024--1033},
  volume = {86},
  date = {1991-12},
  doi = {10.1080/01621459.1991.10475148},
  journaltitle = {Journal of the American Statistical Association},
  abstract = {The bootstrap is proposed as a method for assessing the precision of Gaussian maximum likelihood estimates of the parameters of linear state-space models. Our results also apply to autoregressive moving average models, since they are a special case of state-space models. It is shown that for a time-invariant, stable system, the bootstrap applied to the innovations yields asymptotically consistent standard errors. To investigate the performance of the bootstrap for finite sample lengths, simulation results are presented for a two-state model with 50 and 100 observations; two cases are investigated, one with real characteristic roots and one with complex characteristic roots. The bootstrap is then applied to two real data sets, one used in a test for efficient capital markets and one used to develop an autoregressive integrated moving average model for quarterly earnings data. We find the bootstrap to be of definite value over the conventional asymptotics.},
  publisher = {Informa {UK} Limited},
}

@Article{Tibshirani-1996,
  author = {Robert Tibshirani},
  date = {1996-01},
  journaltitle = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  title = {Regression shrinkage and selection via the lasso},
  doi = {10.1111/j.2517-6161.1996.tb02080.x},
  issn = {1467-9868},
  number = {1},
  pages = {267--288},
  volume = {58},
  abstract = {We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
  publisher = {Oxford University Press (OUP)},
}

@Article{vanHouwelingen-Zwinderman-Stijnen-1993,
  author = {Hans C. {van Houwelingen} and Koos H. Zwinderman and Theo Stijnen},
  date = {1993-12},
  journaltitle = {Statistics in Medicine},
  title = {A bivariate approach to meta-analysis},
  doi = {10.1002/sim.4780122405},
  issn = {1097-0258},
  number = {24},
  pages = {2273--2284},
  volume = {12},
  abstract = {The usual meta-analysis of a sequence of randomized clinical trials only considers the difference between two treatments and produces a point estimate and a confidence interval for a parameter that measures this difference. The usual parameter is the log(odds ratio) linked to Mantel-Haenszel methodology. Inference is made either under the assumption of homogeneity or in a random effects model that takes account of heterogeneity between trials. This paper has two goals. The first is to present a likelihood based method for the estimation of the parameters in the random effects model, which avoids the use of approximating Normal distributions. The second goal is to extend this method to a bivariate random effects model, in which the effects in both groups are supposed random. In this way inference can be made about the relationship between improvement and baseline effect. The method is demonstrated by a meta-analysis dataset of Collins and Langman.},
  publisher = {Wiley},
}

@Article{VonKorff-Simon-1996,
  author = {Michael {Von Korff} and Gregory Simon},
  date = {1996-06},
  journaltitle = {British Journal of Psychiatry},
  title = {The relationship between pain and depression},
  doi = {10.1192/s0007125000298474},
  issn = {1472-1465},
  number = {S30},
  pages = {101--108},
  volume = {168},
  abstract = {Empirical results from epidemiological studies on pain-depression comorbidity in primary care and population samples have shown that: (a) pain is as strongly associated with anxiety as with depressive disorders; (b) characteristics that most strongly predict depression are diffuseness of pain and the extent to which pain interferes with activities; (c) certain psychological symptoms (low energy, disturbed sleep, worry) are prominent among pain patients, while others (guilt, loneliness) are not; (d) depression and pain dysfunction are evident early in the natural history of pain, but dysfunction and distress are often transient; and (e) among initially dysfunctional pain patients whose dysfunction is chronic, depression levels do not improve but neither do they increase over time with chronicity alone. These results seem consistent with these mechanisms of pain-depression comorbidity; (1) a trait of susceptibility to both dysphoric physical symptoms (including pain) and psychological symptoms (including depression), and a state of somatosensory amplification in which psychological distress amplifies dysphoric physical sensations (including pain); (2) psychological illness and behavioural dysfunction being interrelated features of a maladaptive response to pain evident early in the natural history of the condition, and often resolving during an early recovery phase; (3) pain constituting a significant physical and psychological stressor that may induce or exacerbate psychological distress. Thus, pain and psychological illness should be viewed as having reciprocal psychological and behavioural effects involving both processes of illness expression and adaption, as well as pain having specific effects on emotional state and behavioural function.},
  publisher = {Royal College of Psychiatrists},
}

@Article{Wechsler-Dowdall-Davenport-etal-1995,
  author = {Henry Wechsler and George W. Dowdall and Andrea Davenport and Eric B. Rimm},
  date = {1995-07},
  journaltitle = {American Journal of Public Health},
  title = {A gender-specific measure of binge drinking among college students},
  doi = {10.2105/ajph.85.7.982},
  issn = {1541-0048},
  number = {7},
  pages = {982--985},
  volume = {85},
  publisher = {American Public Health Association},
}
